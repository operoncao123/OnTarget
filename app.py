#!/usr/bin/env python3
"""
OnTarget å¼€æºç‰ˆ - æ— éœ€ç™»å½•çš„æœ¬åœ°æ–‡çŒ®æ¨é€ç³»ç»Ÿ
ä½¿ç”¨å›ºå®šè´¦æˆ· localuser
"""

import os
import sys
import threading
import time
from datetime import datetime, timedelta

base_dir = os.path.dirname(os.path.abspath(__file__))
if base_dir not in sys.path:
    sys.path.insert(0, base_dir)

from functools import wraps

from flask import Flask, render_template, jsonify, request, session, redirect, url_for

env_file = os.path.join(base_dir, '.env')
if os.path.exists(env_file):
    with open(env_file, 'r') as f:
        for line in f:
            line = line.strip()
            if line and not line.startswith('#') and '=' in line:
                key, value = line.split('=', 1)
                os.environ[key] = value

from models.user_manager import UserManager, get_predefined_categories, expand_keywords
from core.cache_manager import SmartCache
from services.push_service import PersonalizedPushEngine, PushScheduler
from core.analyzer import OptimizedAnalyzer, AnalysisQueue
from core.system import LiteraturePushSystemV2
from models.keyword_group_manager import KeywordGroupManager
from utils.encryption import get_encryption_manager

LOCAL_USER_ID = 'localuser'

app = Flask(__name__, template_folder='templates')
app.secret_key = os.getenv('SECRET_KEY', 'ontarget-open-source-secret-key')

base_dir = os.path.dirname(os.path.abspath(__file__))
data_dir = os.path.join(base_dir, 'data')
system = LiteraturePushSystemV2(data_dir)

keyword_group_manager = KeywordGroupManager(db_path=os.path.join(data_dir, 'literature.db'))

encryption_manager = get_encryption_manager()

def ensure_local_user():
    if not system.user_manager.get_user(LOCAL_USER_ID):
        system.user_manager.register_user(LOCAL_USER_ID, 'local@localhost', 'localpass', [])
        print(f"âœ… å·²è‡ªåŠ¨åˆ›å»ºæœ¬åœ°ç”¨æˆ·: {LOCAL_USER_ID}")
    return LOCAL_USER_ID
encryption_manager = get_encryption_manager()

# ============ APIé™æµé…ç½® (V2.6) ============
from flask_limiter import Limiter
from flask_limiter.util import get_remote_address

limiter = Limiter(
    app=app,
    key_func=get_remote_address,
    default_limits=["200 per hour", "50 per minute"],
    storage_uri="memory://"
)

from services.auto_update_service import AutoUpdateService
auto_update_service = AutoUpdateService(system, keyword_group_manager)

@app.errorhandler(429)
def ratelimit_handler(e):
    return jsonify({
        'success': False,
        'error': 'è¯·æ±‚è¿‡äºé¢‘ç¹ï¼Œè¯·ç¨åå†è¯•',
        'retry_after': e.description
    }), 429

@app.after_request
def add_security_headers(response):
    response.headers['X-Frame-Options'] = 'SAMEORIGIN'
    response.headers['X-Content-Type-Options'] = 'nosniff'
    response.headers['X-XSS-Protection'] = '1; mode=block'
    response.headers['Referrer-Policy'] = 'strict-origin-when-cross-origin'
    if request.path.startswith('/api/'):
        response.headers['Cache-Control'] = 'no-store, no-cache, must-revalidate'
        response.headers['Pragma'] = 'no-cache'
    return response

# ============ å¼‚æ­¥æ›´æ–°ä»»åŠ¡ç®¡ç† ============
# å­˜å‚¨æ›´æ–°ä»»åŠ¡çŠ¶æ€: {user_id: {'status': 'running'|'completed'|'failed', 'result': {...}, 'started_at': ..., 'completed_at': ...}}
update_tasks = {}
update_tasks_lock = threading.Lock()

def run_update_task(user_id):
    """åœ¨åå°çº¿ç¨‹è¿è¡Œæ›´æ–°ä»»åŠ¡"""
    try:
        with update_tasks_lock:
            update_tasks[user_id] = {
                'status': 'running',
                'result': None,
                'started_at': datetime.now(),
                'completed_at': None,
                'message': 'æ­£åœ¨è·å–æ–‡çŒ®...'
            }
        
        print(f"[åå°ä»»åŠ¡] å¼€å§‹ä¸ºç”¨æˆ· {user_id} æ›´æ–°æ–‡çŒ®")
        
        # æ‰§è¡Œæ›´æ–°
        result = system.run_for_user(user_id)
        
        # ä¿å­˜æœ€åæ›´æ–°æ—¶é—´åˆ°ç”¨æˆ·åå¥½
        try:
            system.user_manager.update_preferences(user_id, {
                'last_manual_update_at': datetime.now().isoformat(),
                'last_manual_update_result': {
                    'fetched': result.get('fetched', 0),
                    'from_cache': result.get('from_cache', 0),
                    'new_analysis': result.get('new_analysis', 0)
                }
            })
        except Exception as e:
            print(f"[åå°ä»»åŠ¡] ä¿å­˜æ›´æ–°æ—¶é—´å¤±è´¥: {e}")
        
        with update_tasks_lock:
            update_tasks[user_id] = {
                'status': 'completed',
                'result': result,
                'started_at': update_tasks[user_id]['started_at'],
                'completed_at': datetime.now(),
                'message': f"è·å–å®Œæˆ: {result.get('fetched', 0)} ç¯‡æ–°æ–‡çŒ®"
            }
        
        print(f"[åå°ä»»åŠ¡] ç”¨æˆ· {user_id} æ›´æ–°å®Œæˆ: {result}")
        
    except Exception as e:
        print(f"[åå°ä»»åŠ¡] ç”¨æˆ· {user_id} æ›´æ–°å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        
        with update_tasks_lock:
            update_tasks[user_id] = {
                'status': 'failed',
                'result': {'error': str(e)},
                'started_at': update_tasks[user_id].get('started_at', datetime.now()),
                'completed_at': datetime.now(),
                'message': f'æ›´æ–°å¤±è´¥: {str(e)}'
            }

def cleanup_old_tasks():
    with update_tasks_lock:
        now = datetime.now()
        expired_users = []
        for user_id, task in update_tasks.items():
            if task.get('completed_at') and (now - task['completed_at']).total_seconds() > 3600:
                expired_users.append(user_id)
        for user_id in expired_users:
            del update_tasks[user_id]
            print(f"[æ¸…ç†] å·²åˆ é™¤ç”¨æˆ· {user_id} çš„æ—§ä»»åŠ¡è®°å½•")

def start_cleanup_timer():
    def cleanup_loop():
        while True:
            time.sleep(1800)
            cleanup_old_tasks()
    
    cleanup_thread = threading.Thread(target=cleanup_loop, daemon=True)
    cleanup_thread.start()
    print("[ç³»ç»Ÿ] åå°æ¸…ç†ä»»åŠ¡å·²å¯åŠ¨")

start_cleanup_timer()

from models.simple_db import get_db
_db = get_db()
print("âœ… æ•°æ®åº“åˆå§‹åŒ–å®Œæˆ")

ensure_local_user()

if not app.debug or os.environ.get('WERKZEUG_RUN_MAIN') == 'true':
    try:
        auto_update_service.start()
        print("âœ… è‡ªåŠ¨æ›´æ–°æœåŠ¡å·²å¯åŠ¨")
    except Exception as e:
        print(f"âš ï¸ è‡ªåŠ¨æ›´æ–°æœåŠ¡å¯åŠ¨å¤±è´¥: {e}")

def get_current_user_id():
    ensure_local_user()
    return LOCAL_USER_ID

def login_required(f):
    @wraps(f)
    def decorated_function(*args, **kwargs):
        session['user_id'] = LOCAL_USER_ID
        session['username'] = LOCAL_USER_ID
        return f(*args, **kwargs)
    return decorated_function

@app.route('/')
def index():
    ensure_local_user()
    groups = keyword_group_manager.get_user_groups(LOCAL_USER_ID)
    if not groups:
        return redirect('/keywords')
    return render_template('v2_dashboard.html')

@app.route('/keywords')
@login_required
def keywords_page():
    return render_template('v2_keywords.html')

@app.route('/api/user/public/<username>')
def api_get_user_public(username):
    return jsonify({'success': False, 'error': 'å¼€æºç‰ˆä¸æ”¯æŒå…¬å¼€ç”¨æˆ·é¡µé¢'}), 404

@app.route('/api/user/me')
@login_required
def api_get_user():
    user_id = get_current_user_id()
    user = system.user_manager.get_user(user_id)
    if user:
        return jsonify({
            'success': True,
            'user': {
                'id': user_id,
                'username': user.get('username', ''),
                'email': user.get('email', ''),
                'keywords': user.get('keywords', []),
                'preferences': user.get('preferences', {}),
                'avatar': user.get('avatar', ''),
                'stats': system.push_engine.get_user_stats(user_id)
            }
        })
    return jsonify({'success': False, 'error': 'ç”¨æˆ·ä¸å­˜åœ¨'}), 404


# API: æ›´æ–°ç”¨æˆ·å…³é”®è¯
@app.route('/api/user/keywords', methods=['POST'])
@login_required
def api_update_keywords():
    """æ›´æ–°ç”¨æˆ·å…³é”®è¯"""
    data = request.json
    user_id = get_current_user_id()
    
    selected_categories = data.get('categories', [])
    custom_keywords = data.get('custom_keywords', '')
    
    # å±•å¼€å…³é”®è¯
    keywords = expand_keywords(selected_categories)
    if custom_keywords:
        custom_list = [k.strip() for k in custom_keywords.split(',') if k.strip()]
        keywords.extend(custom_list)
    
    keywords = list(set(keywords))
    
    result = system.user_manager.update_keywords(user_id, keywords)
    
    if result['success']:
        return jsonify({
            'success': True,
            'keywords': keywords,
            'message': 'å…³é”®è¯å·²æ›´æ–°'
        })
    else:
        return jsonify({'success': False, 'error': result['error']}), 400

# ==================== å…³é”®è¯ç»„ç®¡ç† API ====================

# API: è·å–ç”¨æˆ·çš„å…³é”®è¯ç»„åˆ—è¡¨
@app.route('/api/user/keyword-groups')
@login_required
def api_get_keyword_groups():
    """è·å–ç”¨æˆ·çš„æ‰€æœ‰å…³é”®è¯ç»„"""
    user_id = get_current_user_id()
    
    # æ£€æŸ¥æ˜¯å¦åŒ…å«å·²ç¦ç”¨çš„ç»„
    include_inactive = request.args.get('include_inactive', 'false').lower() == 'true'
    
    # è·å–ç”¨æˆ·çš„æ‰€æœ‰ç»„
    groups = keyword_group_manager.get_user_groups(user_id, include_inactive=include_inactive)
    
    return jsonify({
        'success': True,
        'groups': groups
    })

# API: è·å–ç”¨æˆ·å…³é”®è¯ç»„æ±‡æ€»ï¼ˆç”¨äºDashboardï¼‰
@app.route('/api/user/keyword-groups/summary')
@login_required
def api_get_keyword_groups_summary():
    """è·å–ç”¨æˆ·å…³é”®è¯ç»„çš„æ±‡æ€»ä¿¡æ¯"""
    user_id = get_current_user_id()
    
    summary = keyword_group_manager.get_user_groups_summary(user_id)
    
    return jsonify({
        'success': True,
        'summary': summary
    })

# API: åˆ›å»ºå…³é”®è¯ç»„
@app.route('/api/user/keyword-groups', methods=['POST'])
@login_required
def api_create_keyword_group():
    """åˆ›å»ºæ–°çš„å…³é”®è¯ç»„"""
    user_id = get_current_user_id()
    data = request.json
    
    # éªŒè¯å¿…å¡«å­—æ®µ
    name = data.get('name', '').strip()
    keywords = data.get('keywords', [])
    
    if not name:
        return jsonify({'success': False, 'error': 'ç»„åç§°ä¸èƒ½ä¸ºç©º'}), 400
    
    if not keywords or len(keywords) == 0:
        return jsonify({'success': False, 'error': 'å…³é”®è¯ä¸èƒ½ä¸ºç©º'}), 400
    
    # åˆ›å»ºç»„
    result = keyword_group_manager.create_group(
        user_id=user_id,
        name=name,
        keywords=keywords,
        icon=data.get('icon', 'ğŸ”¬'),
        color=data.get('color', '#5a9a8f'),
        description=data.get('description', ''),
        match_mode=data.get('match_mode', 'any'),
        min_match_score=data.get('min_match_score', 0.3)
    )
    
    if result['success']:
        return jsonify({
            'success': True,
            'group_id': result['group_id'],
            'group': result['group'],
            'message': 'å…³é”®è¯ç»„åˆ›å»ºæˆåŠŸ'
        })
    else:
        return jsonify({'success': False, 'error': result['error']}), 400

# API: æ›´æ–°å…³é”®è¯ç»„
@app.route('/api/user/keyword-groups/<group_id>', methods=['PUT'])
@login_required
def api_update_keyword_group(group_id):
    """æ›´æ–°å…³é”®è¯ç»„"""
    user_id = get_current_user_id()
    data = request.json
    
    # æ£€æŸ¥ç»„æ˜¯å¦å­˜åœ¨
    group = keyword_group_manager.get_group(user_id, group_id)
    if not group:
        return jsonify({'success': False, 'error': 'å…³é”®è¯ç»„ä¸å­˜åœ¨'}), 404
    
    # æ›´æ–°ç»„
    result = keyword_group_manager.update_group(user_id, group_id, data)
    
    if result['success']:
        return jsonify({
            'success': True,
            'group': result['group'],
            'message': 'å…³é”®è¯ç»„æ›´æ–°æˆåŠŸ'
        })
    else:
        return jsonify({'success': False, 'error': result['error']}), 400

# API: åˆ é™¤å…³é”®è¯ç»„
@app.route('/api/user/keyword-groups/<group_id>', methods=['DELETE'])
@login_required
def api_delete_keyword_group(group_id):
    """åˆ é™¤å…³é”®è¯ç»„"""
    user_id = get_current_user_id()
    
    result = keyword_group_manager.delete_group(user_id, group_id)
    
    if result['success']:
        return jsonify({
            'success': True,
            'message': 'å…³é”®è¯ç»„å·²åˆ é™¤'
        })
    else:
        return jsonify({'success': False, 'error': result['error']}), 400

# API: é‡æ–°æ’åºå…³é”®è¯ç»„
@app.route('/api/user/keyword-groups/reorder', methods=['PUT'])
@login_required
def api_reorder_keyword_groups():
    """é‡æ–°æ’åºå…³é”®è¯ç»„"""
    user_id = get_current_user_id()
    data = request.json
    group_order = data.get('group_order', [])
    
    if not group_order:
        return jsonify({'success': False, 'error': 'æ’åºåˆ—è¡¨ä¸èƒ½ä¸ºç©º'}), 400
    
    result = keyword_group_manager.reorder_groups(user_id, group_order)
    
    if result['success']:
        return jsonify({
            'success': True,
            'message': 'æ’åºå·²æ›´æ–°'
        })
    else:
        return jsonify({'success': False, 'error': result['error']}), 400

# API: è·å–ç‰¹å®šå…³é”®è¯ç»„çš„æ–‡çŒ®
@app.route('/api/user/keyword-groups/<group_id>/papers')
@login_required
def api_get_group_papers(group_id):
    """è·å–ç‰¹å®šå…³é”®è¯ç»„çš„ä¸ªæ€§åŒ–æ–‡çŒ®"""
    user_id = get_current_user_id()
    
    # è·å–ç»„ä¿¡æ¯
    group = keyword_group_manager.get_group(user_id, group_id)
    if not group:
        return jsonify({'success': False, 'error': 'å…³é”®è¯ç»„ä¸å­˜åœ¨'}), 404
    
    # æ£€æŸ¥ç»„æ˜¯å¦æ¿€æ´»
    if not group.get('is_active', True):
        return jsonify({
            'success': True,
            'papers': [],
            'message': 'è¯¥å…³é”®è¯ç»„å·²ç¦ç”¨'
        })
    
    # ä»ç¼“å­˜è·å–æ‰€æœ‰æ–‡çŒ®
    all_papers = list(system.cache.papers_cache.values())
    
    # è·å–è¯¥ç»„çš„ä¸ªæ€§åŒ–æ–‡çŒ®
    papers = system.push_engine.get_personalized_papers_for_group(
        user_id=user_id,
        group=group,
        available_papers=all_papers,
        limit=50
    )
    
    # è·å–è¯¥ç»„æ”¶è—çš„æ–‡çŒ®
    saved_hashes = keyword_group_manager.get_saved_papers_in_group(user_id, group_id)
    saved_papers = []
    for h in saved_hashes:
        if h in system.cache.papers_cache:
            saved_papers.append(system.cache.papers_cache[h])
    
    # æ›´æ–°è®¿é—®æ—¶é—´
    keyword_group_manager.update_group_access_time(user_id, group_id)
    
    # æ ‡è®°æ–‡çŒ®ä¸ºå·²æµè§ˆï¼ˆå…³é”®è¯ç»„ï¼‰
    paper_hashes = [p['hash'] for p in papers]
    for ph in paper_hashes:
        keyword_group_manager.mark_paper_viewed_in_group(user_id, group_id, ph)
    
    return jsonify({
        'success': True,
        'papers': papers,
        'saved_papers': saved_hashes,
        'group': {
            'id': group['id'],
            'name': group['name'],
            'icon': group.get('icon', 'ğŸ”¬'),
            'color': group.get('color', '#5a9a8f')
        }
    })

# API: åœ¨ç‰¹å®šç»„ä¸­æ”¶è—æ–‡çŒ®
@app.route('/api/user/keyword-groups/<group_id>/papers/<paper_hash>/save', methods=['POST'])
@login_required
def api_save_paper_to_group(group_id, paper_hash):
    """åœ¨ç‰¹å®šå…³é”®è¯ç»„ä¸­æ”¶è—æ–‡çŒ®"""
    user_id = get_current_user_id()
    
    # æ£€æŸ¥ç»„æ˜¯å¦å­˜åœ¨
    group = keyword_group_manager.get_group(user_id, group_id)
    if not group:
        return jsonify({'success': False, 'error': 'å…³é”®è¯ç»„ä¸å­˜åœ¨'}), 404
    
    # æ”¶è—æ–‡çŒ®
    result = keyword_group_manager.save_paper_to_group(user_id, group_id, paper_hash)
    
    if result['success']:
        return jsonify({
            'success': True,
            'message': 'æ–‡çŒ®å·²æ”¶è—åˆ°è¯¥ç»„'
        })
    else:
        return jsonify({'success': False, 'error': result['error']}), 400

# API: åœ¨ç‰¹å®šç»„ä¸­å–æ¶ˆæ”¶è—æ–‡çŒ®
@app.route('/api/user/keyword-groups/<group_id>/papers/<paper_hash>/save', methods=['DELETE'])
@login_required
def api_unsave_paper_from_group(group_id, paper_hash):
    """åœ¨ç‰¹å®šå…³é”®è¯ç»„ä¸­å–æ¶ˆæ”¶è—æ–‡çŒ®"""
    user_id = get_current_user_id()
    
    # æ£€æŸ¥ç»„æ˜¯å¦å­˜åœ¨
    group = keyword_group_manager.get_group(user_id, group_id)
    if not group:
        return jsonify({'success': False, 'error': 'å…³é”®è¯ç»„ä¸å­˜åœ¨'}), 404
    
    # å–æ¶ˆæ”¶è—
    result = keyword_group_manager.unsave_paper_from_group(user_id, group_id, paper_hash)
    
    if result['success']:
        return jsonify({
            'success': True,
            'message': 'æ–‡çŒ®å·²å–æ¶ˆæ”¶è—'
        })
    else:
        return jsonify({'success': False, 'error': result['error']}), 400

# API: è·å–é¢„è®¾å…³é”®è¯åˆ†ç±»
@app.route('/api/keywords/categories')
def api_get_categories():
    """è·å–é¢„è®¾å…³é”®è¯åˆ†ç±»"""
    categories_dict = get_predefined_categories()
    # å°†å­—å…¸è½¬æ¢ä¸ºæ•°ç»„æ ¼å¼ï¼Œæ–¹ä¾¿å‰ç«¯ä½¿ç”¨
    categories_list = []
    for name, data in categories_dict.items():
        categories_list.append({
            'name': name,
            'icon': data.get('icon', 'ğŸ“š'),
            'keywords': data.get('keywords', [])
        })
    return jsonify({
        'success': True,
        'categories': categories_list
    })

# ==================== ç”¨æˆ·è®¾ç½® API ====================

# API: è·å–ç”¨æˆ·è®¾ç½®
@app.route('/api/user/settings')
@login_required
def api_get_user_settings():
    """è·å–ç”¨æˆ·è®¾ç½®"""
    user_id = get_current_user_id()
    
    settings = system.user_manager.get_user_settings(user_id)
    
    if settings is None:
        return jsonify({'success': False, 'error': 'ç”¨æˆ·ä¸å­˜åœ¨'}), 404
    
    return jsonify({
        'success': True,
        'settings': settings
    })

# API: æ›´æ–°ç”¨æˆ·è®¾ç½®
@app.route('/api/user/settings', methods=['PUT'])
@login_required
def api_update_user_settings():
    """æ›´æ–°ç”¨æˆ·è®¾ç½®"""
    user_id = get_current_user_id()
    data = request.get_json()
    
    if not data:
        return jsonify({'success': False, 'error': 'æ— æ•ˆçš„è¯·æ±‚æ•°æ®'})
    
    # å¤„ç†APIè®¾ç½®
    if 'api_provider' in data or 'api_key' in data or 'api_base_url' in data or 'model' in data:
        api_settings = {
            'api_provider': data.get('api_provider'),
            'api_key': data.get('api_key'),
            'api_base_url': data.get('api_base_url'),
            'model': data.get('model')
        }
        result = system.user_manager.save_user_api_settings(user_id, api_settings)
        if not result['success']:
            return jsonify(result), 400
    
    # å¤„ç†æ›´æ–°é¢‘ç‡è®¾ç½®
    if 'update_frequency_days' in data or 'max_auto_analyze' in data:
        update_settings = {
            'update_frequency_days': data.get('update_frequency_days'),
            'max_auto_analyze': data.get('max_auto_analyze')
        }
        result = system.user_manager.save_user_update_settings(user_id, update_settings)
        if not result['success']:
            return jsonify(result), 400
    
    # å¤„ç†æ–‡çŒ®æºè®¾ç½®
    if 'sources' in data:
        sources = data.get('sources', [])
        if isinstance(sources, list):
            result = system.user_manager.save_user_sources(user_id, sources)
            if not result['success']:
                return jsonify(result), 400
    
    return jsonify({
        'success': True,
        'message': 'è®¾ç½®å·²ä¿å­˜'
    })

# API: è·å–ç³»ç»Ÿé»˜è®¤APIé…ç½®ï¼ˆä¸åŒ…å«å¯†é’¥ï¼‰
@app.route('/api/user/system-api-info')
def api_get_system_api_info():
    """è·å–ç³»ç»Ÿé»˜è®¤APIé…ç½®ä¿¡æ¯"""
    return jsonify({
        'success': True,
        'has_system_api': bool(os.getenv('DEEPSEEK_API_KEY')),
        'default_provider': 'deepseek',
        'default_model': 'deepseek-chat'
    })

# API: ä¿®æ”¹å¯†ç 
@app.route('/api/user/change-password', methods=['POST'])
@login_required
def api_change_password():
    """ä¿®æ”¹ç”¨æˆ·å¯†ç """
    data = request.get_json()
    if not data:
        return jsonify({'success': False, 'error': 'æ— æ•ˆçš„è¯·æ±‚æ•°æ®'}), 400
    
    current_password = data.get('current_password', '')
    new_password = data.get('new_password', '')
    
    if not current_password or not new_password:
        return jsonify({'success': False, 'error': 'è¯·æä¾›å½“å‰å¯†ç å’Œæ–°å¯†ç '}), 400
    
    if len(new_password) < 6:
        return jsonify({'success': False, 'error': 'æ–°å¯†ç è‡³å°‘6ä½'}), 400
    
    user_id = get_current_user_id()
    
    # éªŒè¯å½“å‰å¯†ç 
    user = system.user_manager.get_user(user_id)
    if not user:
        return jsonify({'success': False, 'error': 'ç”¨æˆ·ä¸å­˜åœ¨'}), 404
    
    # æ£€æŸ¥å½“å‰å¯†ç æ˜¯å¦æ­£ç¡®
    from models.user_manager import UserManager
    user_manager = UserManager()
    login_result = user_manager.login(user['username'], current_password)
    
    if not login_result['success']:
        return jsonify({'success': False, 'error': 'å½“å‰å¯†ç ä¸æ­£ç¡®'}), 401
    
    # æ›´æ–°å¯†ç 
    try:
        result = system.user_manager.reset_password(user_id, new_password)
        if result['success']:
            return jsonify({'success': True, 'message': 'å¯†ç ä¿®æ”¹æˆåŠŸ'})
        else:
            return jsonify({'success': False, 'error': result.get('error', 'ä¿®æ”¹å¤±è´¥')}), 500
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500

# API: è·å–å¯ç”¨çš„æ–‡çŒ®æº
@app.route('/api/sources/available')
def api_get_available_sources():
    """è·å–æ‰€æœ‰å¯ç”¨çš„æ–‡çŒ®æº"""
    from v1.fetcher import PaperFetcher
    sources = PaperFetcher.get_available_sources()
    return jsonify({
        'success': True,
        'sources': sources
    })

        # API: è·å–ä¸ªæ€§åŒ–æ–‡çŒ®æ¨é€
@app.route('/api/papers/personalized')
@login_required
def api_get_personalized_papers():
    """è·å–ä¸ªæ€§åŒ–æ–‡çŒ®åˆ—è¡¨ï¼ˆV2.6 æ”¯æŒåˆ†é¡µï¼‰"""
    user_id = get_current_user_id()

    if not user_id:
        return jsonify({'success': False, 'error': 'ç”¨æˆ·ä¸å­˜åœ¨'}), 404

    # è·å–ç”¨æˆ·ä¿¡æ¯
    if user_id not in system.user_manager.users:
        return jsonify({'success': False, 'error': 'ç”¨æˆ·ä¸å­˜åœ¨'}), 404

    user = system.user_manager.users[user_id]
    user_keywords = user.get('keywords', [])

    if not user_keywords:
        return jsonify({
            'success': True,
            'papers': [],
            'saved_papers': [],
            'total': 0,
            'message': 'è¯·å…ˆè®¾ç½®å…³é”®è¯'
        })

    # V2.6 ä¼˜åŒ–ï¼šè·å–åˆ†é¡µå‚æ•°
    try:
        page = int(request.args.get('page', 1))
        per_page = int(request.args.get('per_page', 20))
    except (ValueError, TypeError):
        page = 1
        per_page = 20

    # é™åˆ¶æ¯é¡µæœ€å¤§æ•°é‡ï¼Œé˜²æ­¢å†…å­˜æº¢å‡º
    per_page = min(per_page, 50)
    page = max(page, 1)

    # æ£€æŸ¥æ˜¯å¦æŒ‡å®šäº†å…³é”®è¯ç»„
    group_id = request.args.get('group_id')

    if group_id:
        # ä½¿ç”¨ç‰¹å®šå…³é”®è¯ç»„
        group = keyword_group_manager.get_group(user_id, group_id)
        if not group:
            return jsonify({'success': False, 'error': 'å…³é”®è¯ç»„ä¸å­˜åœ¨'}), 404

        if not group.get('is_active', True):
            return jsonify({
                'success': True,
                'papers': [],
                'saved_papers': [],
                'total': 0,
                'message': 'è¯¥å…³é”®è¯ç»„å·²ç¦ç”¨'
            })

        # è·å–è¯¥ç»„çš„å…³é”®è¯
        user_keywords = group.get('keywords', [])

        # è·å–è¯¥ç»„æ”¶è—çš„æ–‡çŒ®ï¼ˆåªæŸ¥è¯¢ä¸€æ¬¡ï¼‰
        saved_papers = keyword_group_manager.get_saved_papers_in_group(user_id, group_id)
        saved_set = set(saved_papers)

        # è·å–ç”¨æˆ·çš„æ‰€æœ‰æ”¶è—ï¼ˆç”¨äº"ä»…æ”¶è—"ç­›é€‰ï¼‰- æ‰¹é‡è·å–ï¼Œå‡å°‘è¯·æ±‚æ¬¡æ•°
        global_saved_papers = keyword_group_manager.get_all_saved_papers_for_user(user_id)
        global_saved_set = set(global_saved_papers)

        # ä»ç¼“å­˜è·å–æ‰€æœ‰æ–‡çŒ®å¹¶ç­›é€‰
        all_papers = list(system.cache.papers_cache.values())
        scored_papers = system.push_engine.get_personalized_papers_for_group(
            user_id=user_id,
            group=group,
            available_papers=all_papers,
            limit=100  # å†…éƒ¨é™åˆ¶æœ€å¤šè¿”å›100ç¯‡ï¼Œé¿å…å†…å­˜æº¢å‡º
        )

        # æ ‡è®°æ˜¯å¦å·²åœ¨å½“å‰ç»„æ”¶è—
        for paper in scored_papers:
            paper['is_saved'] = paper['hash'] in saved_set

        # V2.6 ä¼˜åŒ–ï¼šæœåŠ¡ç«¯åˆ†é¡µ
        total = len(scored_papers)
        start_idx = (page - 1) * per_page
        end_idx = start_idx + per_page
        paginated_papers = scored_papers[start_idx:end_idx]

        # åªæœ‰ç¬¬ä¸€é¡µæ‰æ ‡è®°ä¸ºå·²æµè§ˆï¼ˆé¿å…é‡å¤æ ‡è®°ï¼‰
        if page == 1:
            # æ ‡è®°æ–‡çŒ®ä¸ºå·²æµè§ˆï¼ˆå…¨å±€ï¼‰
            paper_hashes = [p['hash'] for p in paginated_papers]
            system.push_engine.mark_papers_as_seen(user_id, paper_hashes)

            # æ ‡è®°æ–‡çŒ®ä¸ºå·²æµè§ˆï¼ˆå…³é”®è¯ç»„ï¼‰
            for ph in paper_hashes:
                keyword_group_manager.mark_paper_viewed_in_group(user_id, group_id, ph)

        # æ›´æ–°è®¿é—®æ—¶é—´
        keyword_group_manager.update_group_access_time(user_id, group_id)

        # è¿”å›ç»“æœï¼ˆåŒ…å«åˆ†é¡µä¿¡æ¯ï¼‰
        return jsonify({
            'success': True,
            'papers': paginated_papers,
            'saved_papers': saved_papers,
            'global_saved_papers': global_saved_papers,
            'total': total,
            'pagination': {
                'page': page,
                'per_page': per_page,
                'total_pages': (total + per_page - 1) // per_page,
                'has_next': end_idx < total,
                'has_prev': page > 1
            },
            'group': {
                'id': group['id'],
                'name': group['name'],
                'icon': group.get('icon', 'ğŸ”¬'),
                'color': group.get('color', '#5a9a8f'),
                'keywords': group.get('keywords', [])
            }
        })
    
    # å¦‚æœæ²¡æœ‰æŒ‡å®šç»„ï¼Œä½¿ç”¨æ‰€æœ‰æ¿€æ´»ç»„çš„å…³é”®è¯ï¼ˆæˆ–å‘åå…¼å®¹ï¼‰
    # ä»ç¼“å­˜è·å–æ–‡çŒ®
    paper_hashes = system.cache.find_papers_by_keywords(user_keywords)
    papers = system.cache.batch_get_papers(paper_hashes)
    
    # è·å–ç”¨æˆ·æ”¶è—çš„æ–‡çŒ®ï¼ˆå…¨å±€ï¼‰
    saved_papers = []
    if user_id in system.push_engine.user_papers:
        saved_papers = system.push_engine.user_papers[user_id].get('saved_papers', [])
    
    # ä¸ºæ¯ç¯‡æ–‡çŒ®è®¡ç®—ä¸ªæ€§åŒ–åˆ†æ•°
    scored_papers = []
    for paper in papers:
        paper_copy = paper.copy()
        score = system.push_engine._calculate_paper_score(paper, user_keywords)
        paper_copy['personalized_score'] = score
        paper_copy['hash'] = paper.get('hash', system.cache._get_paper_hash(paper))
        paper_copy['is_saved'] = paper_copy['hash'] in saved_papers
        scored_papers.append(paper_copy)
    
    # æŒ‰åˆ†æ•°æ’åº
    scored_papers.sort(key=lambda x: x.get('personalized_score', 0), reverse=True)
    
    # è·å–åˆ†é¡µå‚æ•°
    try:
        page = int(request.args.get('page', 1))
        per_page = int(request.args.get('per_page', 50))
    except:
        page = 1
        per_page = 50
    
    # åˆ†é¡µ
    start_idx = (page - 1) * per_page
    end_idx = start_idx + per_page
    paged_papers = scored_papers[start_idx:end_idx]
    
    # V2.6 ä¼˜åŒ–ï¼šæœåŠ¡ç«¯åˆ†é¡µï¼Œåªæ ‡è®°å½“å‰é¡µçš„æ–‡çŒ®ä¸ºå·²æµè§ˆ
    if page == 1:
        paper_hashes = [p['hash'] for p in paged_papers]
        system.push_engine.mark_papers_as_seen(user_id, paper_hashes)

    # V2.6 ä¼˜åŒ–ï¼šè¿”å›åˆ†é¡µåçš„æ–‡çŒ®ï¼ŒåŒ…å«å®Œæ•´åˆ†é¡µä¿¡æ¯
    total = len(scored_papers)
    return jsonify({
        'success': True,
        'papers': paged_papers,  # V2.6 ä¿®å¤ï¼šè¿”å›åˆ†é¡µåçš„æ–‡çŒ®
        'saved_papers': saved_papers,
        'total': total,
        'pagination': {
            'page': page,
            'per_page': per_page,
            'total_pages': (total + per_page - 1) // per_page,
            'has_next': end_idx < total,
            'has_prev': page > 1
        }
    })

# API: ä¿å­˜/å–æ¶ˆä¿å­˜æ–‡çŒ®
@app.route('/api/papers/save', methods=['POST'])
@login_required
def api_save_paper():
    """ä¿å­˜æ–‡çŒ®åˆ°å…³é”®è¯ç»„"""
    data = request.json
    user_id = get_current_user_id()
    paper_hash = data.get('paper_hash')
    group_id = data.get('group_id')
    
    if not paper_hash:
        return jsonify({'success': False, 'error': 'ç¼ºå°‘æ–‡çŒ®æ ‡è¯†'}), 400
    
    if not group_id:
        return jsonify({'success': False, 'error': 'ç¼ºå°‘å…³é”®è¯ç»„ID'}), 400
    
    # ä¿å­˜åˆ°æŒ‡å®šç»„
    result = keyword_group_manager.save_paper_to_group(user_id, group_id, paper_hash)
    
    if result['success']:
        return jsonify({
            'success': True,
            'message': 'æ–‡çŒ®å·²æ”¶è—åˆ°è¯¥ç»„'
        })
    else:
        return jsonify(result), 400

@app.route('/api/papers/unsave', methods=['POST'])
@login_required
def api_unsave_paper():
    """ä»å…³é”®è¯ç»„å–æ¶ˆä¿å­˜æ–‡çŒ®"""
    data = request.json
    user_id = get_current_user_id()
    paper_hash = data.get('paper_hash')
    group_id = data.get('group_id')
    
    if not paper_hash:
        return jsonify({'success': False, 'error': 'ç¼ºå°‘æ–‡çŒ®æ ‡è¯†'}), 400
    
    if not group_id:
        return jsonify({'success': False, 'error': 'ç¼ºå°‘å…³é”®è¯ç»„ID'}), 400
    
    # ä»æŒ‡å®šç»„ç§»é™¤æ”¶è—
    result = keyword_group_manager.unsave_paper_from_group(user_id, group_id, paper_hash)
    
    if result['success']:
        return jsonify({
            'success': True,
            'message': 'æ–‡çŒ®å·²ä»è¯¥ç»„å–æ¶ˆæ”¶è—'
        })
    else:
        return jsonify(result), 400

# API: è·å–æ–‡çŒ®åœ¨å“ªäº›ç»„è¢«æ”¶è—
@app.route('/api/papers/<paper_hash>/saved-groups', methods=['GET'])
@login_required
def api_get_paper_saved_groups(paper_hash):
    """è·å–æ–‡çŒ®æ”¶è—çš„æ‰€æœ‰ç»„"""
    user_id = get_current_user_id()
    
    # è·å–ç”¨æˆ·çš„æ‰€æœ‰ç»„
    groups = keyword_group_manager.get_user_groups(user_id, include_inactive=False)
    
    # æ£€æŸ¥æ¯ä¸ªç»„æ˜¯å¦æ”¶è—äº†è¯¥æ–‡çŒ®
    saved_groups = []
    for group in groups:
        is_saved = keyword_group_manager.is_paper_saved_in_group(user_id, group['id'], paper_hash)
        if is_saved:
            saved_groups.append({
                'id': group['id'],
                'name': group['name'],
                'icon': group.get('icon', 'ğŸ”¬'),
                'color': group.get('color', '#5a9a8f')
            })
    
    return jsonify({
        'success': True,
        'paper_hash': paper_hash,
        'saved_groups': saved_groups,
        'count': len(saved_groups)
    })

# API: è§¦å‘æ›´æ–°
@app.route('/api/trigger-update', methods=['POST'])
@login_required
@limiter.limit("3 per minute")
def api_trigger_update():
    """æ‰‹åŠ¨è§¦å‘æ–‡çŒ®æ›´æ–° - å¼‚æ­¥ç‰ˆæœ¬"""
    user_id = get_current_user_id()
    
    # æ¸…ç†æ—§ä»»åŠ¡è®°å½•
    cleanup_old_tasks()
    
    with update_tasks_lock:
        # æ£€æŸ¥æ˜¯å¦å·²æœ‰æ­£åœ¨è¿è¡Œçš„ä»»åŠ¡
        if user_id in update_tasks:
            task = update_tasks[user_id]
            if task['status'] == 'running':
                return jsonify({
                    'success': False,
                    'error': 'æ›´æ–°æ­£åœ¨è¿›è¡Œä¸­ï¼Œè¯·ç¨åå†è¯•',
                    'status': 'running'
                }), 429
    
    try:
        # å¯åŠ¨åå°çº¿ç¨‹æ‰§è¡Œæ›´æ–°
        thread = threading.Thread(target=run_update_task, args=(user_id,))
        thread.daemon = True
        thread.start()
        
        return jsonify({
            'success': True,
            'message': 'æ›´æ–°ä»»åŠ¡å·²å¯åŠ¨ï¼Œæ­£åœ¨åå°è¿è¡Œä¸­',
            'status': 'started'
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

# API: æŸ¥è¯¢æ›´æ–°çŠ¶æ€
@app.route('/api/update-status', methods=['GET'])
@login_required
def api_get_update_status():
    """è·å–å½“å‰æ›´æ–°ä»»åŠ¡çŠ¶æ€"""
    user_id = get_current_user_id()
    
    with update_tasks_lock:
        if user_id not in update_tasks:
            return jsonify({
                'success': True,
                'status': 'idle',
                'message': 'æ²¡æœ‰æ­£åœ¨è¿›è¡Œçš„æ›´æ–°ä»»åŠ¡'
            })
        
        task = update_tasks[user_id]
        response = {
            'success': True,
            'status': task['status'],
            'message': task.get('message', ''),
            'started_at': task.get('started_at').isoformat() if task.get('started_at') else None,
        }
        
        if task['status'] == 'completed':
            response['result'] = task.get('result', {})
            response['completed_at'] = task.get('completed_at').isoformat() if task.get('completed_at') else None
        elif task['status'] == 'failed':
            response['error'] = task.get('result', {}).get('error', 'æœªçŸ¥é”™è¯¯')
            response['completed_at'] = task.get('completed_at').isoformat() if task.get('completed_at') else None
        
        return jsonify(response)

@app.route('/api/stats')
@login_required
def api_get_stats():
    """è·å–ç³»ç»Ÿç»Ÿè®¡"""
    user_id = get_current_user_id()
    
    # è·å–è¯¥ç”¨æˆ·æ‰€æœ‰å…³é”®è¯ç»„çš„æ–‡çŒ®æ€»æ•°
    user_groups = keyword_group_manager.get_user_groups(user_id)
    user_keywords = []
    for group in user_groups:
        user_keywords.extend(group.get('keywords', []))
    
    # å¦‚æœæ²¡æœ‰å…³é”®è¯ç»„ï¼Œä»ç”¨æˆ· preferences ä¸­è·å–å…³é”®è¯ï¼ˆå‘åå…¼å®¹ï¼‰
    if not user_keywords:
        user = system.user_manager.get_user(user_id)
        if user and user.get('preferences'):
            user_keywords = user['preferences'].get('keywords', [])
    
    user_keywords = list(set(user_keywords))
    
    # è®¡ç®—åŒ¹é…çš„æ–‡çŒ®æ•°é‡
    # ä»æ•°æ®åº“è·å–æ‰€æœ‰æ–‡çŒ®å¹¶å®æ—¶ç­›é€‰
    all_papers = system.cache.get_all_papers()
    scored_papers = []
    for paper in all_papers:
        score = system.push_engine._calculate_paper_score(paper, user_keywords)
        if score > 0:
            scored_papers.append(paper)
    user_total_papers = len(scored_papers)
    
    # æ·»åŠ ç”¨æˆ·ä¸ªäººç»Ÿè®¡
    user_stats = system.push_engine.get_user_stats(user_id)
    
    return jsonify({
        'success': True,
        'total_papers': user_total_papers,
        'user': user_stats
    })

# API: åˆ†æå¾…å¤„ç†æ–‡çŒ®
@app.route('/api/analyze-pending', methods=['POST'])
@login_required
def api_analyze_pending():
    """åˆ†æå¾…å¤„ç†çš„æ–‡çŒ®"""
    user_id = get_current_user_id()
    
    # è·å–ç”¨æˆ·å…³é”®è¯
    if user_id not in system.user_manager.users:
        return jsonify({'success': False, 'error': 'ç”¨æˆ·ä¸å­˜åœ¨'}), 404
    
    user = system.user_manager.users[user_id]
    user_keywords = user.get('keywords', [])
    
    if not user_keywords:
        return jsonify({'success': False, 'error': 'ç”¨æˆ·æœªè®¾ç½®å…³é”®è¯'})
    
    try:
        # è·å–ç”¨æˆ·ä¸“å±åˆ†æå™¨
        user_analyzer = system.get_user_analyzer(user_id)
        
        # ä»ç¼“å­˜è·å–æ–‡çŒ®
        paper_hashes = system.cache.find_papers_by_keywords(user_keywords)
        papers = system.cache.batch_get_papers(paper_hashes)
        
        # åˆ†ææœªåˆ†æçš„æ–‡çŒ®
        analyzed_count = 0
        for paper in papers:
            if not paper.get('is_analyzed', False):
                # è°ƒç”¨ç”¨æˆ·ä¸“å±åˆ†æå™¨
                analysis = user_analyzer.analyze_paper(
                    paper.get('title', ''),
                    paper.get('abstract', '')
                )
                
                if analysis and not analysis.get('error'):
                    # ç¿»è¯‘æ‘˜è¦ï¼ˆä½¿ç”¨ç”¨æˆ·ä¸“å±åˆ†æå™¨ï¼‰
                    abstract = paper.get('abstract', '')
                    abstract_cn = ''
                    if abstract and len(abstract) > 50:
                        abstract_cn = user_analyzer.translate_abstract(abstract)
                    
                    # ç¡®ä¿æ‰€æœ‰å€¼ä¸ºå­—ç¬¦ä¸²ï¼ˆå¤„ç†å…ƒç»„å’ŒåµŒå¥—ç»“æ„ï¼‰
                    def to_str(v):
                        if v is None:
                            return ''
                        if isinstance(v, (tuple, list)):
                            if len(v) == 0:
                                return ''
                            return to_str(v[0])
                        if isinstance(v, dict):
                            for k in ['main_findings', 'innovations', 'limitations', 'future_directions', 'abstract_cn']:
                                if k in v and v[k]:
                                    return to_str(v[k])
                            return str(v)
                        return str(v) if v else ''
                    
                    # ç¼“å­˜åˆ†æç»“æœ
                    paper_hash = paper.get('hash')
                    if paper_hash:
                        system.cache.cache_analysis(
                            paper.get('title', ''),
                            abstract,
                            {
                                'main_findings': to_str(analysis.get('main_findings', '')),
                                'innovations': to_str(analysis.get('innovations', '')),
                                'limitations': to_str(analysis.get('limitations', '')),
                                'future_directions': to_str(analysis.get('future_directions', '')),
                                'abstract_cn': to_str(abstract_cn)
                            },
                            paper_hash=paper_hash
                        )
                    
                    # åŒæ—¶æ›´æ–°æ–‡çŒ®ç¼“å­˜ä¸­çš„åˆ†æç»“æœ
                    paper_hash = paper.get('hash')
                    if paper_hash and paper_hash in system.cache.papers_cache:
                        system.cache.papers_cache[paper_hash]['is_analyzed'] = True
                        system.cache.papers_cache[paper_hash]['main_findings'] = to_str(analysis.get('main_findings', ''))
                        system.cache.papers_cache[paper_hash]['innovations'] = to_str(analysis.get('innovations', ''))
                        system.cache.papers_cache[paper_hash]['limitations'] = to_str(analysis.get('limitations', ''))
                        system.cache.papers_cache[paper_hash]['future_directions'] = to_str(analysis.get('future_directions', ''))
                        system.cache.papers_cache[paper_hash]['abstract_cn'] = to_str(abstract_cn)
                    
                    analyzed_count += 1
        
        return jsonify({
            'success': True,
            'analyzed_count': analyzed_count
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

# API: åˆ†æå•ç¯‡æ–‡çŒ® (V2.6 å¼‚æ­¥ç‰ˆæœ¬)
@app.route('/api/analyze-paper', methods=['POST'])
@login_required
@limiter.limit("10 per minute")
def api_analyze_paper():
    """åˆ†æå•ç¯‡æ–‡çŒ® - V2.6 æ”¯æŒå¼‚æ­¥é˜Ÿåˆ—"""
    user_id = get_current_user_id()
    data = request.get_json()
    paper_hash = data.get('paper_hash')
    # V2.6: æ–°å¢ async å‚æ•°ï¼Œæ”¯æŒåŒæ­¥æˆ–å¼‚æ­¥æ¨¡å¼
    async_mode = data.get('async', True)  # é»˜è®¤å¼‚æ­¥æ¨¡å¼

    if not paper_hash:
        return jsonify({'success': False, 'error': 'ç¼ºå°‘paper_hashå‚æ•°'})

    try:
        # è·å–æ–‡çŒ®
        paper = system.cache.get_paper(paper_hash)
        if not paper:
            return jsonify({'success': False, 'error': 'æ–‡çŒ®ä¸å­˜åœ¨'})

        title = paper.get('title', '')
        abstract = paper.get('abstract', '')

        if not title or not abstract:
            return jsonify({'success': False, 'error': 'æ–‡çŒ®æ ‡é¢˜æˆ–æ‘˜è¦ä¸ºç©º'})

        # æ£€æŸ¥æ˜¯å¦å·²æœ‰ç¼“å­˜åˆ†æ
        cached = system.cache.get_cached_analysis(title, abstract)
        if cached:
            # æ›´æ–°paperè¡¨
            paper.update(cached)
            paper['is_analyzed'] = True

            # ä¿å­˜åˆ°æ•°æ®åº“
            system.cache.cache_analysis(title, abstract, cached, paper_hash=paper_hash)

            return jsonify({
                'success': True,
                'analyzed': False,
                'message': 'å·²æœ‰ç¼“å­˜åˆ†æç»“æœ',
                'analysis': cached
            })

        # V2.6: å¼‚æ­¥åˆ†ææ¨¡å¼
        if async_mode:
            # å¯¼å…¥å¼‚æ­¥é˜Ÿåˆ—
            from core.async_queue import get_analysis_queue

            task_id = f"analyze_{user_id}_{paper_hash}"

            # æ£€æŸ¥æ˜¯å¦å·²åœ¨é˜Ÿåˆ—ä¸­
            queue = get_analysis_queue(max_workers=2)
            status = queue.get_status(task_id)

            if status and status['status'] in ['pending', 'running']:
                return jsonify({
                    'success': True,
                    'async': True,
                    'task_id': task_id,
                    'status': status['status'],
                    'message': 'åˆ†æä»»åŠ¡å·²åœ¨é˜Ÿåˆ—ä¸­'
                })

            # è·å–ç”¨æˆ·åˆ†æå™¨é…ç½®
            user_analyzer = system.get_user_analyzer(user_id)

            # å®šä¹‰åˆ†æä»»åŠ¡å‡½æ•°
            def do_analysis(analyzer, title, abstract, paper_hash):
                try:
                    # åˆ†ææ–‡çŒ®
                    analysis = analyzer.analyze_paper(title, abstract)

                    if not analysis or analysis.get('error'):
                        return {'error': analysis.get('error', 'åˆ†æå¤±è´¥')}

                    # ç¿»è¯‘æ‘˜è¦
                    abstract_cn = ''
                    if abstract and len(abstract) > 50:
                        abstract_cn = analyzer.translate_abstract(abstract)

                    # ç¡®ä¿å€¼ä¸ºå­—ç¬¦ä¸²
                    def to_str(v):
                        if v is None:
                            return ''
                        if isinstance(v, (tuple, list)):
                            if len(v) == 0:
                                return ''
                            return to_str(v[0])
                        if isinstance(v, dict):
                            for k in ['main_findings', 'innovations', 'limitations', 'future_directions', 'abstract_cn']:
                                if k in v and v[k]:
                                    return to_str(v[k])
                            return str(v)
                        return str(v) if v else ''

                    result = {
                        'main_findings': to_str(analysis.get('main_findings', '')),
                        'innovations': to_str(analysis.get('innovations', '')),
                        'limitations': to_str(analysis.get('limitations', '')),
                        'future_directions': to_str(analysis.get('future_directions', '')),
                        'abstract_cn': to_str(abstract_cn) if not abstract_cn.startswith('ç¿»è¯‘å¤±è´¥') else ''
                    }

                    # ä¿å­˜åˆ°ç¼“å­˜
                    from core.cache_manager import SmartCache
                    cache = SmartCache()
                    cache.cache_analysis(title, abstract, result, paper_hash=paper_hash)

                    return result
                except Exception as e:
                    return {'error': str(e)}

            # æäº¤å¼‚æ­¥ä»»åŠ¡
            result = queue.submit(
                task_id=task_id,
                func=do_analysis,
                args=(user_analyzer, title, abstract, paper_hash),
                priority=5
            )

            if result['success']:
                return jsonify({
                    'success': True,
                    'async': True,
                    'task_id': task_id,
                    'status': 'submitted',
                    'message': 'åˆ†æä»»åŠ¡å·²æäº¤ï¼Œè¯·ç¨åæŸ¥è¯¢ç»“æœ'
                })
            else:
                return jsonify({
                    'success': False,
                    'error': result.get('error', 'æäº¤ä»»åŠ¡å¤±è´¥')
                })

        else:
            # åŒæ­¥æ¨¡å¼ï¼ˆå…¼å®¹æ—§ç‰ˆæœ¬ï¼‰
            user_analyzer = system.get_user_analyzer(user_id)
            analysis = user_analyzer.analyze_paper(title, abstract)

            if not analysis or analysis.get('error'):
                return jsonify({'success': False, 'error': analysis.get('error', 'åˆ†æå¤±è´¥')})

            # ç¿»è¯‘æ‘˜è¦
            abstract_cn = ''
            if abstract and len(abstract) > 50:
                abstract_cn = user_analyzer.translate_abstract(abstract)

            # ç¡®ä¿å€¼ä¸ºå­—ç¬¦ä¸²
            def to_str(v):
                if v is None:
                    return ''
                if isinstance(v, (tuple, list)):
                    if len(v) == 0:
                        return ''
                    return to_str(v[0])
                if isinstance(v, dict):
                    for k in ['main_findings', 'innovations', 'limitations', 'future_directions', 'abstract_cn']:
                        if k in v and v[k]:
                            return to_str(v[k])
                    return str(v)
                return str(v) if v else ''

            result = {
                'main_findings': to_str(analysis.get('main_findings', '')),
                'innovations': to_str(analysis.get('innovations', '')),
                'limitations': to_str(analysis.get('limitations', '')),
                'future_directions': to_str(analysis.get('future_directions', '')),
                'abstract_cn': to_str(abstract_cn) if not abstract_cn.startswith('ç¿»è¯‘å¤±è´¥') else ''
            }

            # ä¿å­˜åˆ°ç¼“å­˜å’Œæ•°æ®åº“
            system.cache.cache_analysis(title, abstract, result, paper_hash=paper_hash)

            return jsonify({
                'success': True,
                'analyzed': True,
                'analysis': result
            })

    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

# API: æŸ¥è¯¢åˆ†æä»»åŠ¡çŠ¶æ€ (V2.6 æ–°å¢)
@app.route('/api/analyze-status/<task_id>')
@login_required
def api_analyze_status(task_id):
    """æŸ¥è¯¢å¼‚æ­¥åˆ†æä»»åŠ¡çŠ¶æ€"""
    try:
        from core.async_queue import get_analysis_queue
        queue = get_analysis_queue()
        status = queue.get_status(task_id)

        if not status:
            return jsonify({
                'success': False,
                'error': 'ä»»åŠ¡ä¸å­˜åœ¨'
            }), 404

        return jsonify({
            'success': True,
            'task_id': task_id,
            'status': status['status'],
            'result': status.get('result'),
            'error': status.get('error')
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/user/auto-update-settings', methods=['GET'])
@login_required
def api_get_auto_update_settings():
    """è·å–ç”¨æˆ·è‡ªåŠ¨æ›´æ–°è®¾ç½®"""
    user_id = get_current_user_id()
    
    try:
        settings = auto_update_service.get_user_schedule_info(user_id)
        settings['recommended_intervals'] = auto_update_service.get_recommended_intervals()
        
        return jsonify({
            'success': True,
            'settings': settings
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/user/auto-update-settings', methods=['PUT'])
@login_required
def api_save_auto_update_settings():
    """ä¿å­˜ç”¨æˆ·è‡ªåŠ¨æ›´æ–°è®¾ç½®"""
    user_id = get_current_user_id()
    data = request.get_json()
    
    if data is None:
        return jsonify({
            'success': False,
            'error': 'ç¼ºå°‘è¯·æ±‚æ•°æ®'
        }), 400
    
    enabled = data.get('enabled', False)
    interval_days = data.get('interval_days', 2)
    
    try:
        # æ›´æ–°è°ƒåº¦
        auto_update_service.update_user_schedule(user_id, enabled, interval_days)
        
        # ä¿å­˜åˆ°ç”¨æˆ· preferences
        system.user_manager.update_preferences(user_id, {
            'auto_update_enabled': enabled,
            'auto_update_interval_days': interval_days
        })
        
        return jsonify({
            'success': True,
            'message': 'è‡ªåŠ¨æ›´æ–°è®¾ç½®å·²ä¿å­˜'
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/user/last-update-info')
@login_required
def api_get_last_update_info():
    """è·å–ç”¨æˆ·æœ€åæ›´æ–°ä¿¡æ¯"""
    user_id = get_current_user_id()
    
    try:
        info = auto_update_service.get_user_schedule_info(user_id)
        
        return jsonify({
            'success': True,
            'last_update_at': info.get('last_update_at'),
            'last_update_result': info.get('last_update_result'),
            'auto_update_enabled': info.get('enabled', False)
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/user/all-saved-papers')
@login_required
def api_get_all_saved_papers():
    """è·å–ç”¨æˆ·æ‰€æœ‰æ”¶è—çš„æ–‡çŒ®ï¼ˆè·¨æ‰€æœ‰ç»„ï¼‰"""
    user_id = get_current_user_id()
    
    try:
        # è·å–æ‰€æœ‰æ”¶è—çš„æ–‡çŒ®å“ˆå¸Œ
        saved_hashes = keyword_group_manager.get_all_saved_papers_for_user(user_id)
        
        if not saved_hashes:
            return jsonify({
                'success': True,
                'papers': [],
                'saved_hashes': [],
                'total': 0
            })
        
        # ä»ç¼“å­˜è·å–æ–‡çŒ®è¯¦æƒ…
        papers = []
        missing_hashes = []
        for paper_hash in saved_hashes:
            paper = system.cache.get_cached_paper(paper_hash)
            if paper:
                # æ ‡è®°ä¸ºå·²æ”¶è—
                paper_copy = paper.copy()
                paper_copy['is_saved'] = True
                papers.append(paper_copy)
            else:
                # è®°å½•ç¼ºå¤±çš„æ–‡çŒ®
                missing_hashes.append(paper_hash)
        
        return jsonify({
            'success': True,
            'papers': papers,
            'saved_hashes': saved_hashes,
            'missing_hashes': missing_hashes,
            'total': len(saved_hashes)
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

# å¥åº·æ£€æŸ¥
@app.route('/api/health')
def api_health():
    """å¥åº·æ£€æŸ¥"""
    return jsonify({
        'status': 'healthy',
        'version': '2.0',
        'timestamp': datetime.now().isoformat()
    })

if __name__ == '__main__':
    host = os.getenv('WEB_HOST', '0.0.0.0')
    port = int(os.getenv('WEB_PORT', '5000'))
    debug = os.getenv('WEB_DEBUG', 'True').lower() == 'true'
    
    print(f"\n{'='*60}")
    print(f"V2 æ–‡çŒ®æ¨é€ç³»ç»Ÿå¯åŠ¨")
    print(f"è®¿é—®åœ°å€: http://localhost:{port}")
    print(f"{'='*60}\n")
    
    app.run(host=host, port=port, debug=debug)
